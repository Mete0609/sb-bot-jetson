import os
import time
import numpy as np
import pyaudio
import wave
from dashscope.audio.asr import Recognition
from http import HTTPStatus
from dashscope import MultiModalConversation
import json
import dashscope
from dashscope.audio.tts_v2 import *
import os
from playsound import playsound  # å¯¼å…¥ playsound åº“ç”¨äºæ’­æ”¾éŸ³é¢‘
import rclpy
from rclpy.node import Node
from std_msgs.msg import String


# ----------- å‚æ•°è®¾ç½® -----------
VOLUME_THRESHOLD = 800    # éŸ³é‡é˜ˆå€¼
SILENCE_DURATION = 2       # é™éŸ³æŒç»­æ—¶é—´é˜ˆå€¼ (ç§’)
RECORD_SECONDS_LIMIT = 60  # æœ€é•¿å½•éŸ³æ—¶é—´ï¼ˆé¿å…æ— é™å½•éŸ³ï¼‰
WAV_OUTPUT_FILENAME = 'asr_input.wav'
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK = 1024
FORMAT = pyaudio.paInt16

# ----------- éŸ³é‡è®¡ç®—å‡½æ•° -----------
def calculate_volume(audio_data):
    audio_np = np.frombuffer(audio_data, dtype=np.int16)
    if len(audio_np) == 0:
        return 0.0

    audio_np = audio_np.astype(np.float32)  # âš¡æ³¨æ„ï¼Œä¸€å®šè¦å…ˆè½¬float32ï¼

    power = np.mean(audio_np ** 2)

    if np.isnan(power) or np.isinf(power) or power < 0:
        return 0.0

    rms = np.sqrt(power)
    return rms

# ----------- å¼€å§‹å½•éŸ³å‡½æ•° -----------
def record_audio_when_voice_detected():
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=SAMPLE_RATE,
                    input=True,
                    frames_per_buffer=CHUNK)

    print("ç­‰å¾…éŸ³é‡è¾¾åˆ°é˜ˆå€¼å¼€å§‹å½•éŸ³...")

    frames = []
    recording = False
    silence_start = None

    while True:
        data = stream.read(CHUNK, exception_on_overflow=False)
        volume = calculate_volume(data)
        print(f"å½“å‰éŸ³é‡ï¼š{volume}")

        current_time = time.time()

        if volume > VOLUME_THRESHOLD:
            if not recording:
                print("æ£€æµ‹åˆ°å£°éŸ³ï¼Œå¼€å§‹å½•éŸ³ï¼")
                recording = True
            frames.append(data)
            silence_start = None  # éŸ³é‡å¤§äº†å°±æ¸…é™¤é™éŸ³è®¡æ—¶
        else:
            if recording:
                if silence_start is None:
                    silence_start = current_time  # ç¬¬ä¸€æ¬¡è¿›å…¥é™éŸ³ï¼Œå¼€å§‹è®¡æ—¶
                    print("è¿›å…¥é™éŸ³æ£€æµ‹...")
                elif (current_time - silence_start) > SILENCE_DURATION:
                    print("æ£€æµ‹åˆ°é™éŸ³è¶…è¿‡2ç§’ï¼Œåœæ­¢å½•éŸ³ã€‚")
                    break  # è¶…è¿‡2ç§’é™éŸ³ï¼Œåœæ­¢å½•éŸ³

    print("ä¿å­˜å½•éŸ³åˆ° asr_input.wav")
    stream.stop_stream()
    stream.close()
    p.terminate()

    wf = wave.open(WAV_OUTPUT_FILENAME, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(SAMPLE_RATE)
    wf.writeframes(b''.join(frames))
    wf.close()


# ----------- è°ƒç”¨ASRè¯†åˆ«å‡½æ•° -----------
def recognize_audio():
    recognition = Recognition(
        model='paraformer-realtime-v2',
        format='wav',
        sample_rate=16000,
        language_hints=['zh', 'en'],
        callback=None
    )
    result = recognition.call(WAV_OUTPUT_FILENAME)

    if result.status_code == HTTPStatus.OK:
        print('è¯†åˆ«ç»“æœï¼š')
        sentences = result.get_sentence()
        if sentences and isinstance(sentences, list):
            for sentence in sentences:
                if 'text' in sentence:
                    print(sentence['text'])
                    return sentence['text']
                else:
                    print("è¯¥å¥æ— textå­—æ®µ")
        else:
            print("æœªè¿”å›æœ‰æ•ˆè¯†åˆ«å†…å®¹ã€‚")
    else:
        print('Error: ', result.message)

def LLM_sent_message(sentence):
    messages = [
        {
            "role": "system",
            "content": [
                {
                    "text": """
                        ä½ æ˜¯ä¸€ä¸ªå®¶åº­é™ªæŠ¤æœºå™¨äººï¼Œåå­—æ˜¯å‚»å®ã€‚ä½ æ ¹æ®ç”¨æˆ·çš„ä¿¡æ¯ï¼Œä¸¥æ ¼è¾“å‡ºæ ‡å‡†JSONæ ¼å¼ï¼Œéµå¾ªä»¥ä¸‹è¦æ±‚ï¼š
                        - å±æ€§åå’Œå€¼å¿…é¡»ä½¿ç”¨åŒå¼•å·("")ã€‚
                        - æ¯ä¸ªå¯¹è±¡æœ€åä¸€é¡¹åä¸å¾—æ·»åŠ é€—å·ã€‚
                        - ä¸èƒ½æ·»åŠ æ³¨é‡Šæˆ–é¢å¤–è§£é‡Šã€‚
                        - <>é‡Œçš„å†…å®¹ä½¿ç”¨ä¸­æ–‡ï¼Œæœ€å¤§é•¿åº¦ä¸è¶…è¿‡100å­—
                        {
                            "control": {
                                "action": "<åŠ¨ä½œç±»å‹>",
                                "parameters": {
                                    "position": "<ä½ç½®>",
                                    "target":<ç›®æ ‡>
                                }
                            },
                            "response": {
                                "message": "<ä¿¡æ¯>"
                            }
                        }

                        ä¾‹1ï¼š
                        "æˆ‘æƒ³è®©ä½ å»ä¹¦æ¡Œæ‹¿ç“¶æ°´"
                        è¾“å‡ºï¼š
                        {
                            "control": {
                                "action": "move",
                                "parameters": {
                                    "position": "ä¹¦æ¡Œ",
                                    "target":"bottle"
                                }
                            },
                            "response": {
                                "message": "å¥½çš„æˆ‘æ­£åœ¨å‰å¾€ã€‚"
                            }
                        }
                        ä¾‹2ï¼š
                        "è¯·å¸®æˆ‘å»é¤æ¡Œä¸Šæ‹¿çº¸å·¾"
                        è¾“å‡ºï¼š
                        {
                            "control": {
                                "action": "move",
                                "parameters": {
                                    "position": "é¤æ¡Œ",
                                    "target":"tissue"
                                }
                            },
                            "response": {
                                "message": "å¥½çš„æˆ‘æ­£åœ¨å‰å¾€ã€‚"
                            }
                        }
                    """
                }
            ]
        },
        {
            'role': 'user',
            'content': [
                # {'image': 'image_path'},  # å°†å›¾åƒè·¯å¾„ä¼ é€’ç»™æ¨¡å‹ä»¥è¿›è¡Œè¯†åˆ«
                # {'text': 'è¯·å¸®æˆ‘å»å¨æˆ¿æ‹¿ç“¶æ°´ã€‚'}
                {'text': sentence}
            ]
        }
    ]
    response = MultiModalConversation.call(
        # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
        api_key=os.getenv("DASHSCOPE_API_KEY"), 
        model='qwen-vl-max-latest',
        messages=messages)
    print(response["output"]["choices"][0]["message"].content[0]["text"])
    return response["output"]["choices"][0]["message"].content[0]["text"]

def LLM_text_respone(llm_output_text):
    try:
        llm_result = json.loads(llm_output_text)

        # 2. æå– response.message
        if 'response' in llm_result and 'message' in llm_result['response']:
            message_text = llm_result['response']['message']
            return message_text
            # print("æå–åˆ°çš„æœºå™¨äººå›å¤æ˜¯ï¼š", message_text)
        else:
            print("è§£æå¤±è´¥ï¼šæ‰¾ä¸åˆ° response æˆ– message å­—æ®µã€‚")

    except json.JSONDecodeError as e:
        print("è§£æJSONå¤±è´¥ï¼š", e)

def LLM_text_control(input_dict):
    try:
        if isinstance(input_dict, str):
            input_dict = json.loads(input_dict)  # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—å…¸
        
        # è¾“å…¥ç±»å‹æ£€æŸ¥
        if not isinstance(input_dict, dict):
            return "Error: è¾“å…¥å¿…é¡»æ˜¯å­—å…¸ç±»å‹ï¼"
        
        # è·å–æ§åˆ¶éƒ¨åˆ†
        control = input_dict.get("control", {})

        # æ„é€ æ–°çš„å­—å…¸ï¼Œè¿”å›æ§åˆ¶éƒ¨åˆ†
        result = {
            "control": control
        }

        # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
        return json.dumps(result, ensure_ascii=False)

    except Exception as e:
        return f"Error: {e}"


# æ–‡æœ¬è½¬è¯­éŸ³
def Text_To_Speech(LLM_sentence):
    model = "cosyvoice-v2"
    # éŸ³è‰²
    voice = "longxiaoxia_v2"

    # å®ä¾‹åŒ–SpeechSynthesizerï¼Œå¹¶åœ¨æ„é€ æ–¹æ³•ä¸­ä¼ å…¥æ¨¡å‹ï¼ˆmodelï¼‰ã€éŸ³è‰²ï¼ˆvoiceï¼‰ç­‰è¯·æ±‚å‚æ•°
    synthesizer = SpeechSynthesizer(model=model, voice=voice)

    # å‘é€å¾…åˆæˆæ–‡æœ¬ï¼Œè·å–äºŒè¿›åˆ¶éŸ³é¢‘
    # audio = synthesizer.call("ä½ å¥½ï¼Œæˆ‘æ˜¯å‚»å®ï¼Œä½ çš„æ™ºèƒ½é™ªæŠ¤åŠ©æ‰‹ï¼Œè¯·é—®æœ‰èƒ½å¸®å¾—ä¸Šå¿™çš„å—ï¼Ÿ")
    audio = synthesizer.call(LLM_sentence)
    # æ‰“å°è¯·æ±‚çš„å»¶è¿Ÿç­‰ä¿¡æ¯
    print('[Metric] requestId: {}, first package delay ms: {}'.format(
        synthesizer.get_last_request_id(),
        synthesizer.get_first_package_delay()))

    # å°†éŸ³é¢‘ä¿å­˜è‡³æœ¬åœ°
    audio_path = 'output.mp3'
    with open(audio_path, 'wb') as f:
        f.write(audio)

    # æ’­æ”¾ä¿å­˜çš„éŸ³é¢‘
    playsound(audio_path)  # è‡ªåŠ¨æ’­æ”¾éŸ³é¢‘

def app_bridge_control(llm_output_text, node):
    try:
        llm_result = json.loads(llm_output_text)

        control_part = llm_result.get('control', None)

        if control_part is None:
            print("âŒ è§£æå¤±è´¥ï¼šæ²¡æœ‰æ‰¾åˆ° control éƒ¨åˆ†ï¼")
            return False

        msg = String()
        msg.data = json.dumps(control_part, ensure_ascii=False)
        node.publisher_.publish(msg)
        node.get_logger().info(f'ğŸš€ å·²å‘é€æ§åˆ¶æŒ‡ä»¤: {msg.data}')
        return True

    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ å‡ºç°å¼‚å¸¸: {e}")

    return False

def main(args=None):
    rclpy.init(args=args)

    from rclpy.node import Node
    class AppBridgePublisher(Node):
        def __init__(self):
            super().__init__('app_bridge_publisher')
            self.publisher_ = self.create_publisher(String, '/app_navigation_target', 10)

    node = AppBridgePublisher()

    try:
        while True:
            record_audio_when_voice_detected()
            sentence = recognize_audio()
            llm_output_text = LLM_sent_message(sentence)
            TTS_input = LLM_text_respone(llm_output_text)
            # print(f"æ”¶åˆ°çš„llm_output_text: {llm_output_text}")
            Text_To_Speech(TTS_input)
            control_text = LLM_text_control(llm_output_text)
            print(f"æ”¶åˆ°çš„control_text: {control_text}")
            app_bridge_control(control_text, node)  # ä¼ nodeè¿›å»ï¼

    except Exception as e:
        print(f"âŒ ä¸»ç¨‹åºè¿è¡Œå¼‚å¸¸: {e}")
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == "__main__":
    main()
